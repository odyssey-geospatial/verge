{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4",
   "metadata": {
    "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4"
   },
   "source": [
    "### VERGE: Vector-Mode Regional Geospatial Encoding\n",
    "# Initial Embeddings \n",
    "\n",
    "Back in the \"02\" folder, we trained a Masked Geospatial Model.\n",
    "That model can compute a set of embeddings for any tile, \n",
    "for which the inputs are a set of geospatial entities. \n",
    "Thise embeddings are permutation-equivariant (\"perm-e\") \n",
    "with respect to the input features. In thi folder we are building \n",
    "a fully permutation-invariant (\"perm-i\") aggregation of the perm-e\n",
    "outputs. \n",
    "\n",
    "In this notebook, we compute those perm-e embeddings for all instances\n",
    "in our training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8M2z1JqEbum-",
   "metadata": {
    "id": "8M2z1JqEbum-"
   },
   "source": [
    "## Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SDCVXcwwbuNz",
   "metadata": {
    "id": "SDCVXcwwbuNz"
   },
   "outputs": [],
   "source": [
    "# Google colab setup\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_home = '/content/drive/MyDrive/Projects/verge'\n",
    "# os.chdir(project_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jfRkhxK615Hn",
   "metadata": {
    "id": "jfRkhxK615Hn"
   },
   "outputs": [],
   "source": [
    "# !pip install geo_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i_mx-hmv1fmE",
   "metadata": {
    "id": "i_mx-hmv1fmE"
   },
   "outputs": [],
   "source": [
    "# Local processing setup\n",
    "project_home = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L4cSLLSy1jCL",
   "metadata": {
    "id": "L4cSLLSy1jCL"
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c",
   "metadata": {
    "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import json\n",
    "from geo_encodings import MPPEncoder\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_home)\n",
    "from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2",
   "metadata": {
    "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeed93f-aa96-4f8b-8865-507f58adf0b3",
   "metadata": {
    "id": "faeed93f-aa96-4f8b-8865-507f58adf0b3"
   },
   "outputs": [],
   "source": [
    "# The name of the ROI to use.\n",
    "roi_name = 'ne-laptop'\n",
    "\n",
    "# The name of the general-purpose data directory.\n",
    "data_home = '%s/data' % (project_home)\n",
    "\n",
    "# The name of the ROI-specific data directory.\n",
    "roi_home = '%s/data/%s' % (project_home, roi_name)\n",
    "\n",
    "# The unique identifier of the model to be used.\n",
    "run_id = '102'\n",
    "\n",
    "# What type of device to train on.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1",
   "metadata": {
    "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12061fe8-4f75-48bb-9eb3-06216f7b8e74",
   "metadata": {
    "id": "12061fe8-4f75-48bb-9eb3-06216f7b8e74"
   },
   "outputs": [],
   "source": [
    "# Read the ROI definition.\n",
    "fname = '%s/roi.json' % roi_home\n",
    "with open(fname) as source:\n",
    "    roi = json.load(source)\n",
    "\n",
    "tile_size = roi['tile_size']\n",
    "encoding_resolution = roi['encoding_resolution']\n",
    "\n",
    "# We need the dimension of the encoding.\n",
    "encoder = MPPEncoder(\n",
    "    region=[0, 0, tile_size, tile_size],\n",
    "    resolution=encoding_resolution,\n",
    "    center=True\n",
    ")\n",
    "geo_encoding_dim = len(encoder)\n",
    "print('%d elements in encodings' % geo_encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8",
   "metadata": {
    "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8"
   },
   "outputs": [],
   "source": [
    "# Read the list of labels.\n",
    "fname = '%s/labels.csv' % data_home\n",
    "labels = pd.read_csv(fname)\n",
    "n_classes = len(labels)\n",
    "print('%d labels in this dataset' % n_classes)\n",
    "\n",
    "label_id_lookup = {\n",
    "    z['label']: z['id']\n",
    "    for z in labels.to_dict('records')\n",
    "}\n",
    "\n",
    "label_name_lookup = {\n",
    "    z['id']: z['label']\n",
    "    for z in labels.to_dict('records')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86rIhLz3w72",
   "metadata": {
    "id": "d86rIhLz3w72"
   },
   "outputs": [],
   "source": [
    "# Read the file that gives class probabilities.\n",
    "fname = '%s/class_info.csv' % roi_home\n",
    "class_info = pd.read_csv(fname)\n",
    "print('%d class info records' % len(class_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PGWG-XHKFLmq",
   "metadata": {
    "id": "PGWG-XHKFLmq"
   },
   "source": [
    "## Load data\n",
    "We determine which files to read by loading the associated \"split\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b1ff1-08bd-44f6-9d42-9cf7c142d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of AOI tags. They can be found in the splits file.\n",
    "fname = '%s/models/splits-%s.csv' % (roi_home, run_id)\n",
    "splits = pd.read_csv(fname)\n",
    "aoi_tags = np.unique(splits['aoi_tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa310216-b622-42e2-a551-322943108993",
   "metadata": {
    "id": "fa310216-b622-42e2-a551-322943108993"
   },
   "source": [
    "## Prep model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7cab2-c69b-47cd-a574-09011c06d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset constructor requires a lookup table for class probabilities.\n",
    "class_prob_lookup = {\n",
    "    z['label']: z['prob']\n",
    "    for z in class_info.to_dict('records')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eeccb-765f-4e54-8e6d-3dd96b7527f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "model_fname = '%s/models/model-%s' % (roi_home, run_id)\n",
    "model = torch.load(model_fname, weights_only=False)\n",
    "print('loaded %s' % model_fname)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc366b6-585b-4a1f-8320-4a6a8933f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over encoded input files. For each one, define a dataset,\n",
    "# run it through the model, and generate an initial set of embeddings.\n",
    "for aoi_tag in aoi_tags:\n",
    "    \n",
    "    encoding_fname = '%s/encodings/%s.pkl' % (roi_home, aoi_tag)\n",
    "    print('\\n', encoding_fname)\n",
    "\n",
    "    # Define a dataset and datloader for this input file.\n",
    "    # Note that we set the batch size to 1. This effectively removes all\n",
    "    # padding, as the dataloader pads to the largest object\n",
    "    # in the batch. \n",
    "    dataset = VergeDataset([encoding_fname], n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=verge_collate_fn,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Get embeddings for every tile in this AOI.\n",
    "    embeddings_for_this_aoi = []\n",
    "    for features, labels, attention_mask, idents in dataloader:\n",
    "        features = features.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        embeddings = model.embed(features, attention_mask)\n",
    "        embeddings_for_this_aoi.append({\n",
    "            'aoi_tag': idents[0].split(':')[0],\n",
    "            'tile_tag': idents[0].split(':')[1],\n",
    "            'embedding': embeddings\n",
    "        })\n",
    "\n",
    "    # Save those.\n",
    "    ofname = '%s/initials/%s.pkl' % (roi_home, aoi_tag)\n",
    "    os.makedirs(os.path.dirname(ofname), exist_ok=True)\n",
    "    with open(ofname, 'wb') as dest:\n",
    "        pickle.dump(embeddings_for_this_aoi, dest)\n",
    "    print('wrote %s' % ofname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10079b1",
   "metadata": {
    "id": "c10079b1"
   },
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79da7-133d-4f42-ab8e-77eb248cc382",
   "metadata": {
    "id": "41f79da7-133d-4f42-ab8e-77eb248cc382"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
