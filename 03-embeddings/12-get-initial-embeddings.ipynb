{"cells":[{"cell_type":"markdown","id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4","metadata":{"id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4"},"source":["### VERGE: Vector-Mode Regional Geospatial Encoding\n","# Initial Embeddings\n","\n","Back in the \"02\" folder, we trained a Masked Geospatial Model.\n","That model can compute a set of embeddings for any tile,\n","for which the inputs are a set of geospatial entities.\n","These embeddings are permutation-equivariant (\"perm-e\")\n","with respect to the input features,\n","which is not what we want for a regional embedding.\n","In this folder we are building\n","a fully permutation-invariant (\"perm-i\") aggregation of the perm-e\n","outputs.\n","\n","In this notebook, we compute those perm-e embeddings for all instances\n","in our training and validation datasets.\n","That is, we run the model that was trained bac inthe 02 folder.\n"]},{"cell_type":"markdown","id":"8M2z1JqEbum-","metadata":{"id":"8M2z1JqEbum-"},"source":["## Processing Setup"]},{"cell_type":"code","execution_count":null,"id":"SDCVXcwwbuNz","metadata":{"id":"SDCVXcwwbuNz"},"outputs":[],"source":["# Google colab setup\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_home = '/content/drive/MyDrive/Projects/verge'\n","os.chdir(project_home)\n","!pip install geo_encodings"]},{"cell_type":"code","execution_count":null,"id":"i_mx-hmv1fmE","metadata":{"id":"i_mx-hmv1fmE"},"outputs":[],"source":["# Local processing setup\n","# project_home = '..'"]},{"cell_type":"markdown","id":"L4cSLLSy1jCL","metadata":{"id":"L4cSLLSy1jCL"},"source":["## Notebook Setup"]},{"cell_type":"code","execution_count":null,"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c","metadata":{"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import pickle\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import copy\n","import json\n","from geo_encodings import MPPEncoder\n","\n","import sys\n","sys.path.append(project_home)\n","from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n"]},{"cell_type":"markdown","id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2","metadata":{"id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"id":"faeed93f-aa96-4f8b-8865-507f58adf0b3","metadata":{"id":"faeed93f-aa96-4f8b-8865-507f58adf0b3"},"outputs":[],"source":["# The name of the ROI to use.\n","roi_name = 'newengland'\n","\n","# The name of the general-purpose data directory.\n","data_home = '%s/data' % (project_home)\n","\n","# The name of the ROI-specific data directory.\n","roi_home = '%s/data/%s' % (project_home, roi_name)\n","\n","# The unique identifier of the model to be used for initial embeddings.\n","transformer_model_id = '301b'\n","\n","# Identifier of the splits file to use.\n","splits_id = '201'\n","\n","# What type of device to train on.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('using device', device)\n"]},{"cell_type":"markdown","id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1","metadata":{"id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":null,"id":"12061fe8-4f75-48bb-9eb3-06216f7b8e74","metadata":{"id":"12061fe8-4f75-48bb-9eb3-06216f7b8e74"},"outputs":[],"source":["# Read the ROI definition.\n","fname = '%s/roi.json' % roi_home\n","with open(fname) as source:\n","    roi = json.load(source)\n","\n","tile_size = roi['tile_size']\n","encoding_resolution = roi['encoding_resolution']\n","\n","# We need the dimension of the encoding.\n","encoder = MPPEncoder(\n","    region=[0, 0, tile_size, tile_size],\n","    resolution=encoding_resolution,\n","    center=True\n",")\n","geo_encoding_dim = len(encoder)\n","print('%d elements in encodings' % geo_encoding_dim)\n"]},{"cell_type":"code","execution_count":null,"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8","metadata":{"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8"},"outputs":[],"source":["# Read the list of labels.\n","fname = '%s/labels.csv' % data_home\n","labels = pd.read_csv(fname)\n","n_classes = len(labels)\n","print('%d labels in this dataset' % n_classes)\n","\n","label_id_lookup = {\n","    z['label']: z['id']\n","    for z in labels.to_dict('records')\n","}\n","\n","label_name_lookup = {\n","    z['id']: z['label']\n","    for z in labels.to_dict('records')\n","}"]},{"cell_type":"code","execution_count":null,"id":"d86rIhLz3w72","metadata":{"id":"d86rIhLz3w72"},"outputs":[],"source":["# Read the file that gives class probabilities.\n","fname = '%s/class_info.csv' % roi_home\n","class_info = pd.read_csv(fname)\n","print('%d class info records' % len(class_info))"]},{"cell_type":"markdown","id":"PGWG-XHKFLmq","metadata":{"id":"PGWG-XHKFLmq"},"source":["## Load data\n","We determine which files to read by loading the associated \"split\" file."]},{"cell_type":"code","execution_count":null,"id":"2f4b1ff1-08bd-44f6-9d42-9cf7c142d498","metadata":{"id":"2f4b1ff1-08bd-44f6-9d42-9cf7c142d498"},"outputs":[],"source":["# Get the list of AOI tags. They can be found in the splits file.\n","fname = '%s/models/splits-%s.csv' % (roi_home, splits_id)\n","splits = pd.read_csv(fname)\n","aoi_tags = np.unique(splits['aoi_tag'])"]},{"cell_type":"markdown","id":"fa310216-b622-42e2-a551-322943108993","metadata":{"id":"fa310216-b622-42e2-a551-322943108993"},"source":["## Prep model and data"]},{"cell_type":"code","execution_count":null,"id":"3be7cab2-c69b-47cd-a574-09011c06d681","metadata":{"id":"3be7cab2-c69b-47cd-a574-09011c06d681"},"outputs":[],"source":["# The dataset constructor requires a lookup table for class probabilities.\n","class_prob_lookup = {\n","    z['label']: z['prob']\n","    for z in class_info.to_dict('records')\n","}"]},{"cell_type":"code","execution_count":null,"id":"d83eeccb-765f-4e54-8e6d-3dd96b7527f3","metadata":{"id":"d83eeccb-765f-4e54-8e6d-3dd96b7527f3"},"outputs":[],"source":["# Load the model.\n","model_fname = '%s/models/transformer-%s' % (roi_home, transformer_model_id)\n","model = torch.load(model_fname, weights_only=False)\n","print('loaded %s' % model_fname)\n","\n","model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"id":"bfc366b6-585b-4a1f-8320-4a6a8933f5ce","metadata":{"id":"bfc366b6-585b-4a1f-8320-4a6a8933f5ce"},"outputs":[],"source":["# Loop over encoded input files. For each one, define a dataset,\n","# run it through the model, and generate an initial set of embeddings.\n","for aoi_tag in aoi_tags:\n","\n","    encoding_fname = '%s/encodings/%s.pkl' % (roi_home, aoi_tag)\n","    print('\\n%s [%s / %s]' % (encoding_fname, k, len(aoi_tags)))\n","\n","    # Define a dataset and datloader for this input file.\n","    # Note that we set the batch size to 1. This effectively removes all\n","    # padding, as the dataloader pads to the largest object\n","    # in the batch.\n","    dataset = VergeDataset([encoding_fname], n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n","    dataloader = DataLoader(\n","        dataset,\n","        batch_size=1,\n","        shuffle=True,\n","        collate_fn=verge_collate_fn,\n","        drop_last=False\n","    )\n","\n","    # Get embeddings for every tile in this AOI.\n","    embeddings_for_this_aoi = []\n","    for features, labels, attention_mask, idents in dataloader:\n","        features = features.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","        embeddings = model.embed(features, attention_mask)\n","        embeddings_for_this_aoi.append({\n","            'aoi_tag': idents[0].split(':')[0],\n","            'tile_tag': idents[0].split(':')[1],\n","            'embedding': embeddings\n","        })\n","\n","    # Save those.\n","    ofname = '%s/initials/%s.pkl' % (roi_home, aoi_tag)\n","    os.makedirs(os.path.dirname(ofname), exist_ok=True)\n","    with open(ofname, 'wb') as dest:\n","        pickle.dump(embeddings_for_this_aoi, dest)\n","    print('wrote %s' % ofname)\n"]},{"cell_type":"markdown","id":"c10079b1","metadata":{"id":"c10079b1"},"source":["## QA"]},{"cell_type":"code","execution_count":null,"id":"41f79da7-133d-4f42-ab8e-77eb248cc382","metadata":{"id":"41f79da7-133d-4f42-ab8e-77eb248cc382"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}