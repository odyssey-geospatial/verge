{"cells":[{"cell_type":"markdown","id":"3e2daeab-4b8b-411b-84cc-dd88286bf67b","metadata":{"id":"3e2daeab-4b8b-411b-84cc-dd88286bf67b"},"source":["# Apply the trained embedding model to a a batch of locations\n","\n","Here we get VERGE embeddings for a large collection of locations\n","in an region of interest."]},{"cell_type":"markdown","id":"9fdc7f7f-2399-4755-b7db-052b0132479a","metadata":{"id":"9fdc7f7f-2399-4755-b7db-052b0132479a"},"source":["## Processing Setup"]},{"cell_type":"code","execution_count":null,"id":"5856a24c-41a8-45fe-b254-8e4c31b330d9","metadata":{"id":"5856a24c-41a8-45fe-b254-8e4c31b330d9"},"outputs":[],"source":["# Google colab\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_home = '/content/drive/MyDrive/Projects/verge'\n","os.chdir(project_home)\n","!pip install geo_encodings osmnx"]},{"cell_type":"code","execution_count":null,"id":"96eefe45-43a4-4665-8b29-484e2b32ae66","metadata":{"id":"96eefe45-43a4-4665-8b29-484e2b32ae66"},"outputs":[],"source":["# Local processing setup\n","# project_home = '..'"]},{"cell_type":"markdown","id":"928178a0-d593-4266-a683-5f9c5e3830ba","metadata":{"id":"928178a0-d593-4266-a683-5f9c5e3830ba"},"source":["## Notebook Setup"]},{"cell_type":"code","execution_count":null,"id":"45908146-a047-477f-9f71-a417b5bc1c0e","metadata":{"id":"45908146-a047-477f-9f71-a417b5bc1c0e"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from typing import List, Tuple, Optional\n","\n","import pickle\n","import json\n","import copy\n","import pandas as pd\n","import numpy as np\n","import pyproj\n","import shapely\n","import osmnx\n","import geopandas\n","\n","import sys\n","sys.path.append('%s/03-embeddings' % project_home)\n","from embedderv5 import *\n","\n","sys.path.append(project_home)\n","from utils.verge import rules\n"]},{"cell_type":"markdown","id":"48aa408e-db4c-4f59-8a22-993ee4ec5a85","metadata":{"id":"48aa408e-db4c-4f59-8a22-993ee4ec5a85"},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"id":"6886ae2e-4c09-4a9d-8104-5fd506c75ad8","metadata":{"id":"6886ae2e-4c09-4a9d-8104-5fd506c75ad8"},"outputs":[],"source":["# The name of the ROI to use.\n","roi_name = 'newengland'\n","\n","# The name of the general-purpose data directory.\n","data_home = '%s/data' % (project_home)\n","\n","# The name of the ROI-specific data directory.\n","roi_home = '%s/data/%s' % (project_home, roi_name)\n","\n","# The unique identifier of the model to be used.\n","transformer_run_id = '301b'\n","collector_run_id = '301b'"]},{"cell_type":"markdown","id":"6WbnmtGQy6dt","metadata":{"id":"6WbnmtGQy6dt"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":null,"id":"7PWm1IxGy5YD","metadata":{"id":"7PWm1IxGy5YD"},"outputs":[],"source":["# Read the ROI definition.\n","fname = '%s/roi.json' % roi_home\n","with open(fname) as source:\n","    roi = json.load(source)\n","\n","tile_size = roi['tile_size']\n","encoding_resolution = roi['encoding_resolution']\n","\n","roi"]},{"cell_type":"code","execution_count":null,"id":"W0iawwU4HX0V","metadata":{"id":"W0iawwU4HX0V"},"outputs":[],"source":["# Re-define the ROI. The original is taking too long.\n","# this just includes the more urbanized part os sourhtern New England\n","roi['lat0'] =  41.2\n","roi['lon0'] = -73.4\n","\n","# roi['lat1'] = 43.4\n","# roi['lon1'] = -69.7\n","\n","# even smaller:\n","roi['lat1'] = 42.0\n","roi['lon1'] = -72.3\n"]},{"cell_type":"code","execution_count":null,"id":"01be9101-802b-4c1d-8191-d3a666ffbf83","metadata":{"id":"01be9101-802b-4c1d-8191-d3a666ffbf83"},"outputs":[],"source":["# Read the file containing labels.\n","fname = '%s/labels.csv' % data_home\n","labels = pd.read_csv(fname)\n","\n","# Make a lookup table to get a numerical label from a text label.\n","label_lookup = {\n","    z['label']: z['id']\n","    for z in labels.to_dict('records')\n","}\n","label_count = len(label_lookup)\n","label_lookup"]},{"cell_type":"code","execution_count":null,"id":"08288cec-bbfb-4170-81ff-e54a3464b94e","metadata":{"id":"08288cec-bbfb-4170-81ff-e54a3464b94e"},"outputs":[],"source":["# Define a local map projection, using the definition from the ROI file.\n","def get_projections(proj_def):\n","    ltm_crs = pyproj.CRS.from_proj4(proj_def)\n","    wgs84_crs = pyproj.CRS.from_epsg(4326)\n","    proj_forward = pyproj.Transformer.from_crs(wgs84_crs, ltm_crs, always_xy=True).transform\n","    proj_inverse = pyproj.Transformer.from_crs(ltm_crs, wgs84_crs, always_xy=True).transform\n","    return proj_forward, proj_inverse\n","\n","proj_forward, proj_inverse = get_projections(roi['proj_def'])"]},{"cell_type":"code","execution_count":null,"id":"91d1ca56-35e4-47f3-9a0f-eb2cf8563f8a","metadata":{"id":"91d1ca56-35e4-47f3-9a0f-eb2cf8563f8a"},"outputs":[],"source":["# Read the coastline file.\n","fname = '%s/coastlines' % (roi_home)\n","coastlines_gdf = geopandas.read_file(fname)\n","print('%d coastline polygons' % len(coastlines_gdf))\n","\n","def get_land_water(bounds, features):\n","\n","    # Create a baseline polygon consisting of the whole AOI.\n","    landwater = copy.deepcopy(bounds)\n","\n","    # Intersect that with the coastlines data.\n","    coastlines = shapely.union_all(coastlines_gdf['geometry'].values)\n","    landwater = landwater.intersection(coastlines)\n","\n","    # subtract out any polygonal water feature.\n","    for _, f in features.iterrows():\n","        if f['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n","            if f['natural'] == 'water':\n","                landwater = shapely.difference(landwater, f['geometry'])\n","\n","    return landwater"]},{"cell_type":"markdown","id":"13ffc010-4ee2-43ad-b82f-0bfb063c0de7","metadata":{"id":"13ffc010-4ee2-43ad-b82f-0bfb063c0de7"},"source":["## Processing\n"]},{"cell_type":"markdown","id":"03004f1f-80b0-4a86-ad5a-e0de47fb4de3","metadata":{"id":"03004f1f-80b0-4a86-ad5a-e0de47fb4de3"},"source":["### Pull OSM data for the area around this location"]},{"cell_type":"code","execution_count":null,"id":"wj1viNpBFHga","metadata":{"id":"wj1viNpBFHga"},"outputs":[],"source":["import osmnx\n","tags = {\n","    'landuse': True,\n","    'place': True,\n","    'highway': True,\n","    'railway': True,\n","    #'aeroway': True,\n","    'bridge': True,\n","    'tunnel': True,\n","    #'power': True,\n","    'natural': True,\n","    'waterway': True,\n","    'landcover': True,\n","    #'building': True,\n","    'amenity': True,\n","    'shop': True,\n","    'leisure': True\n","}\n"]},{"cell_type":"code","execution_count":null,"id":"cmGS7yRNE1kO","metadata":{"id":"cmGS7yRNE1kO"},"outputs":[],"source":["# We need to break up the ROI into smaller chunks for querying.\n","\n","dd = 0.2 # size of query boxes, in degrees\n","sub_rois = []\n","\n","lon0 = roi['lon0']\n","while lon0 < roi['lon1']:\n","    lon1 = lon0 + dd\n","\n","    lat0 = roi['lat0']\n","    while lat0 < roi['lat1']:\n","        lat1 = lat0 + dd\n","\n","        query_bounds = [lon0, lat0, lon1, lat1]\n","        sub_rois.append(query_bounds)\n","\n","        lat0 += dd\n","\n","    lon0 += dd\n","\n","print('will process %d sub-rois' % len(sub_rois))\n"]},{"cell_type":"code","execution_count":null,"id":"BYOHcY0xIMEi","metadata":{"id":"BYOHcY0xIMEi"},"outputs":[],"source":["for k, sub_roi in enumerate(sub_rois):\n","\n","  print('\\n%d/%d' % (k+1, len(sub_rois)))\n","\n","  # Check whether an output file has already been generarted for this sub-roi.\n","  ofname = '%s/gents/gents_%+.1f_%+.1f.csv' % (roi_home, sub_roi[0], sub_roi[1])\n","  if os.path.exists(ofname):\n","    print('%s already exists; skipping' % ofname)\n","    continue\n","\n","  query_bounds = sub_roi\n","  print(query_bounds)\n","  sub_roi_features = osmnx.features.features_from_bbox(query_bounds, tags=tags).reset_index()\n","  print('%d features from OSM' % len(sub_roi_features))\n","\n","  # Just retain the relevant columns.\n","  columns_in_rules = set(['id', 'geometry', 'amenity', 'highway', 'landuse', 'railway', 'water', 'waterway', 'natural'])\n","  columns_in_features = set(sub_roi_features.columns)\n","  columns_to_keep = list(columns_in_rules.intersection(columns_in_features))\n","  sub_roi_features = sub_roi_features[columns_to_keep]\n","\n","  # Down-select and re-format any relevant geospatial entities (\"gents\").\n","  sub_roi_gents = []\n","  for feature in sub_roi_features.to_dict('records'):\n","\n","      gtype = feature['geometry'].geom_type\n","\n","      for rule in rules:\n","          if gtype == rule['gtype']:\n","              osm_key = rule['osm_key']\n","              if osm_key in feature:\n","                  osm_value = str(feature[osm_key])\n","                  if osm_value in rule['osm_values']:\n","                      geomxy = shapely.ops.transform(proj_forward, feature['geometry'])\n","                      if geomxy.is_empty:\n","                          continue\n","                      sub_roi_gents.append({\n","                          'id': feature['id'],\n","                          'category': rule['gent_category'],\n","                          'label': rule['gent_label'],\n","                          'geom': feature['geometry'],\n","                          'geomxy': geomxy,\n","                          'gtype': gtype\n","                      })\n","\n","\n","  # Create a \"land/water\" polygon.\n","  lon0, lat0, lon1, lat1 = sub_roi\n","  lons = [lon0, lon1, lon1, lon0, lon0]\n","  lats = [lat0, lat0, lat1, lat1, lat0]\n","  lonlat_bounds = shapely.Polygon(list(zip(lons, lats)))\n","  landwater = get_land_water(lonlat_bounds, sub_roi_features)\n","  landwaterxy = shapely.ops.transform(proj_forward, landwater)\n","  sub_roi_gents.append({\n","      'id': None,\n","      'category': 'waterway',\n","      'label': 'land',\n","      'geom': None,\n","      'geomxy': landwaterxy,\n","      'gtype': landwaterxy.geom_type\n","  })\n","\n","  ofname = '%s/gents/gents_%+.1f_%+.1f.csv' % (roi_home, sub_roi[0], sub_roi[1])\n","  os.makedirs(os.path.dirname(ofname), exist_ok=True)\n","  sub_roi_df = pd.DataFrame(sub_roi_gents)\n","  sub_roi_df.to_csv(ofname, index=False)\n","  print('%d records to %s' % (len(sub_roi_df), ofname))\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"2kXIA1ZN2BIr"},"id":"2kXIA1ZN2BIr"},{"cell_type":"code","execution_count":null,"id":"xYNV3oEDOzvI","metadata":{"id":"xYNV3oEDOzvI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fcShEgVvOzgQ","metadata":{"id":"fcShEgVvOzgQ"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"39ea9c28-d608-4990-a28b-be34f30564bc","metadata":{"id":"39ea9c28-d608-4990-a28b-be34f30564bc"},"source":["### Re-organize geo info for this tile"]},{"cell_type":"code","execution_count":null,"id":"741503cf-7180-444f-8e68-201a4b874889","metadata":{"id":"741503cf-7180-444f-8e68-201a4b874889"},"outputs":[],"source":["# Get the bounds for this tile in projected coordinates.\n","buffer = roi['tile_size'] / 2\n","center_x, center_y = proj_forward(center_lon, center_lat)\n","x0, y0 = center_x - buffer, center_y - buffer\n","x1, y1 = center_x + buffer, center_y + buffer\n","xx = [x0, x1, x1, x0, x0]\n","yy = [y0, y0, y1, y1, y0]\n","tile_bbox = shapely.Polygon(list(zip(xx, yy)))"]},{"cell_type":"code","execution_count":null,"id":"836c8241-480b-425c-aa50-9a7039b57ffa","metadata":{"id":"836c8241-480b-425c-aa50-9a7039b57ffa"},"outputs":[],"source":["# Re-project all geospatial entities and clip them to the bounds of this tile.\n","tile_gents = []\n","for gent in gents:\n","    geomxy = shapely.affinity.translate(\n","        gent['geomxy'].intersection(tile_bbox),\n","        xoff=-x0, yoff=-y0\n","    )\n","    if geomxy.is_empty:\n","        continue\n","    tile_gents.append({\n","        'category': gent['category'],\n","        'label': gent['label'],\n","        'geometry': geomxy,\n","        'gtype': gent['gtype'],\n","        'xoff': x0,\n","        'yoff': y0,\n","    })\n","print('%d geospatial entities' % len(tile_gents))\n","pd.DataFrame(tile_gents).head(3)"]},{"cell_type":"markdown","id":"2ec68ef6-4d63-4ecd-beba-c55eef51edb9","metadata":{"id":"2ec68ef6-4d63-4ecd-beba-c55eef51edb9"},"source":["### Apply MPP encoding to all entities in this tile"]},{"cell_type":"code","execution_count":null,"id":"18145826-2e10-4ea7-9961-82bc7a833940","metadata":{"id":"18145826-2e10-4ea7-9961-82bc7a833940"},"outputs":[],"source":["# Define an encoder to use.\n","from geo_encodings import MPPEncoder\n","encoder = MPPEncoder(\n","    region=[0, 0, tile_size, tile_size],\n","    resolution=encoding_resolution,\n","    center=True\n",")\n","geo_encoding_dim = len(encoder)\n","print('%d elements in encodings' % geo_encoding_dim)\n"]},{"cell_type":"code","execution_count":null,"id":"f3fba8c5-262d-450a-b83d-1bc06e7afe35","metadata":{"id":"f3fba8c5-262d-450a-b83d-1bc06e7afe35"},"outputs":[],"source":["# Apply encodings.\n","for gent in tile_gents:\n","    gent['encoding'] = encoder.encode(gent['geometry']).values()\n"]},{"cell_type":"markdown","id":"f5d23843-6bac-40d7-95d4-191641b05ed4","metadata":{"id":"f5d23843-6bac-40d7-95d4-191641b05ed4"},"source":["### Get one-hot label vectors for each entity"]},{"cell_type":"code","execution_count":null,"id":"1bb645e3-6c09-4cb6-b8a7-43c52c3f10b0","metadata":{"id":"1bb645e3-6c09-4cb6-b8a7-43c52c3f10b0"},"outputs":[],"source":["# We will also need the one-hot label vectors for each entity.\n","for gent in tile_gents:\n","    label_name = '%s : %s' % (gent['category'], gent['label'])\n","    label_id = label_lookup[label_name]\n","    label_onehot = np.full(label_count, 0, dtype=float)\n","    label_onehot[label_id] = 1\n","    gent['onehot'] = label_onehot"]},{"cell_type":"code","execution_count":null,"id":"65b15d1f-5573-4156-bd12-8e8cb07232d8","metadata":{"id":"65b15d1f-5573-4156-bd12-8e8cb07232d8"},"outputs":[],"source":["# Display that encoding as a heat map.\n","mpps = np.vstack([z['encoding'] for z in tile_gents])\n","print(mpps.shape)\n","onehots = np.vstack([z['onehot'] for z in tile_gents])\n","print(onehots.shape)\n","\n","tile_encoding = np.hstack([onehots, mpps])\n","print(tile_encoding.shape)"]},{"cell_type":"code","execution_count":null,"id":"c3bd8214-7f46-47fc-888e-18e80b208c25","metadata":{"id":"c3bd8214-7f46-47fc-888e-18e80b208c25"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","data = tile_encoding\n","\n","plt.imshow(data, cmap='viridis', aspect='equal')  # 'viridis' is a good default colormap\n","plt.colorbar(label=\"Value\")  # add a color scale bar\n","plt.title(\"Full Encoding For Tile\")\n","plt.xlabel(\"Encoding Index\")\n","plt.ylabel(\"Entity Number\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"f4823385-1733-4305-8630-48f50247d8b9","metadata":{"id":"f4823385-1733-4305-8630-48f50247d8b9"},"source":["### Initial embedding for this tile"]},{"cell_type":"code","execution_count":null,"id":"56d5f185-be86-492c-81d2-0fdaac23ab36","metadata":{"id":"56d5f185-be86-492c-81d2-0fdaac23ab36"},"outputs":[],"source":["from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n","\n","# Get initial embedding for this tile.\n","transformer = GeospatialTransformer(\n","    feature_dim = geo_encoding_dim + label_count,\n","    model_dim=128,\n","    num_heads=4,\n","    num_layers=4,\n","    num_classes=label_count,\n","    dropout=0.2\n",")\n","\n","model_fname = '%s/models/transformer-%s' % (roi_home, transformer_run_id)\n","transformer = torch.load(model_fname, weights_only=False, map_location=torch.device('cpu'))\n","print('loaded %s' % model_fname)\n","\n","n_param = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n","print('%d trainable parameters in model' % n_param)\n"]},{"cell_type":"code","execution_count":null,"id":"TCBYxpU-wqGg","metadata":{"id":"TCBYxpU-wqGg"},"outputs":[],"source":["input_features = torch.tensor(tile_encoding, dtype=torch.float32).unsqueeze(0)\n","print(input_features.shape)\n","\n","attention_mask = torch.ones(1, tile_encoding.shape[0])\n","\n","input_attention_mask = torch.ones(1, tile_encoding.shape[0], dtype=torch.float32)\n","print(input_attention_mask.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"_1JgSM1Tvz9E","metadata":{"id":"_1JgSM1Tvz9E"},"outputs":[],"source":["transformed = transformer.embed(input_features, input_attention_mask)\n","print(transformed.shape)"]},{"cell_type":"markdown","id":"uK-pkIVOxs2i","metadata":{"id":"uK-pkIVOxs2i"},"source":["### Get the final embedding for this tile"]},{"cell_type":"code","execution_count":null,"id":"-NuHGd14-Atx","metadata":{"id":"-NuHGd14-Atx"},"outputs":[],"source":["import sys\n","sys.path.append('%s/03-embeddings' % project_home)\n","from embedderv5 import ContrastivePairDataset, PermutationInvariantModel, TripletContrastiveLoss, triplet_collate_fn"]},{"cell_type":"code","execution_count":null,"id":"b4d3fb19-8258-4d77-a70b-22020b1abfe7","metadata":{"id":"b4d3fb19-8258-4d77-a70b-22020b1abfe7"},"outputs":[],"source":["# Initialize model\n","embedding_dim = 128\n","model = PermutationInvariantModel(\n","    input_dim=embedding_dim,\n","    hidden_dim=128,\n","    embedding_dim=embedding_dim,\n","    num_attention_heads=8,\n","    num_linear_layers=3,\n","    dropout=0.1\n",")\n","\n","model_fname = '%s/models/collector-%s.pth' % (roi_home, collector_run_id)\n","state_dict = torch.load(model_fname, map_location='cpu')\n","model.load_state_dict(state_dict)\n","print('loaded %s' % model_fname)\n","\n","n_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('%d trainable parameters in model' % n_param)\n"]},{"cell_type":"code","execution_count":null,"id":"h5T7uWao-0eC","metadata":{"id":"h5T7uWao-0eC"},"outputs":[],"source":["transformed.shape"]},{"cell_type":"code","execution_count":null,"id":"2blulE_m_fNF","metadata":{"id":"2blulE_m_fNF"},"outputs":[],"source":["masks = torch.ones(1, tile_encoding.shape[0], dtype=torch.bool)\n","print(masks.shape)"]},{"cell_type":"code","execution_count":null,"id":"7d1jVi51VRy_","metadata":{"id":"7d1jVi51VRy_"},"outputs":[],"source":["\n","emb = model(transformed, masks)"]},{"cell_type":"code","execution_count":null,"id":"jwOUwGGI-9Vg","metadata":{"id":"jwOUwGGI-9Vg"},"outputs":[],"source":["emb.shape"]},{"cell_type":"markdown","id":"sr7ay1wK_2w7","metadata":{"id":"sr7ay1wK_2w7"},"source":[]},{"cell_type":"code","execution_count":null,"id":"NXB5jnFH_w9W","metadata":{"id":"NXB5jnFH_w9W"},"outputs":[],"source":["emb"]},{"cell_type":"code","execution_count":null,"id":"A_EwLnjT_752","metadata":{"id":"A_EwLnjT_752"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}